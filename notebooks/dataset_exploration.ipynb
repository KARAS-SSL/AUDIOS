{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória do Conjunto de Dados\n",
    "\n",
    "### Sumário <a class=\"anchor\" id=\"topo\"></a>\n",
    "\n",
    "* [Parte 1: Configuração do notebook](#part_01)\n",
    "* [Parte 2: Geração do arquivo .csv](#part_02)\n",
    "    * [Parte 2.1: Listagem por Pessoa](#part_02_01)\n",
    "    * [Parte 2.2: Listagem por Arquivo](#part_02_02)\n",
    "* [Parte 3: Análise exploratória dos dados](#part_03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: Configuração do notebook <a class=\"anchor\" id=\"part_01\"></a>\n",
    "\n",
    "Nesta seção, as principais bibliotecas que serão usadas são importadas e as variáveis globais são definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PATH_TO_DATASET = \"/home/lozavival/Documents/AUDIOS-Dataset\"\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Geração do arquivo .csv <a class=\"anchor\" id=\"part_02\"></a>\n",
    "\n",
    "Nesta seção, a estrutura de pastas do dataset é percorrida para criação de um arquivo .csv contendo informações de metadados dos arquivos presentes no dataset.\n",
    "\n",
    "Esse arquivo pode ser gerado em duas versões: uma listagem por pessoa, em que cada linha da tabela contém informações sobre um locutor, ou uma listagem por arquivo, em que cada linha da tabela contém informações sobre um arquivo de áudio específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versão 1: Listagem por Pessoa <a class=\"anchor\" id=\"part_02_01\"></a>\n",
    "\n",
    "Aqui, o dataset é percorrido e é gerado um arquivo .csv com as seguintes informações de cada pessoa:\n",
    "\n",
    "* Nome\n",
    "* Código identificador\n",
    "* Gênero (extraído do código identificador)\n",
    "* Quantidade de arquivos de fala sintetizada\n",
    "* Quantidade de arquivos de fala real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing the name, id, gender and number of spoofed\n",
    "# and bonafide files for each person.\n",
    "fake_audios_path = os.path.join(PATH_TO_DATASET, \"fake_voices\")\n",
    "real_audios_path = os.path.join(PATH_TO_DATASET, \"real_voices\")\n",
    "people = {}\n",
    "\n",
    "# For every spoofed folder, get the number of spoofed files\n",
    "for folder in os.listdir(fake_audios_path):\n",
    "    path = os.path.join(fake_audios_path, folder)\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "\n",
    "    people[person] = {\n",
    "        \"gender\": gender,\n",
    "        \"id\": ids,\n",
    "        \"spoof_count\": len(files),\n",
    "    }\n",
    "\n",
    "# For every bona-fide folder, get the number of bona-fide files\n",
    "for folder in os.listdir(real_audios_path):\n",
    "    path = os.path.join(real_audios_path, folder)\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "\n",
    "    if people.get(person) is not None:\n",
    "        people[person][\"bonafide_count\"] = len(files)\n",
    "    else:\n",
    "        # If the person is not in the dictionary, there are no spoof files\n",
    "        people[person] = {\n",
    "            \"gender\": gender,\n",
    "            \"id\": ids,\n",
    "            \"spoof_count\": 0,\n",
    "            \"bonafide_count\": len(files),\n",
    "        }\n",
    "\n",
    "print(len(people))\n",
    "print(list(people.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dictionary to a .csv file.\n",
    "import csv\n",
    "\n",
    "fields = [\"person\", \"gender\", \"id\", \"spoof_count\", \"bonafide_count\"]\n",
    "with open(os.path.join(PATH_TO_DATASET, \"meta.csv\"), \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    for person, data in people.items():\n",
    "        writer.writerow([person, data[\"gender\"], data[\"id\"], data[\"spoof_count\"], data[\"bonafide_count\"]])\n",
    "print(\"File written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versão 2: Listagem por Arquivo <a class=\"anchor\" id=\"part_02_02\"></a>\n",
    "\n",
    "O dataset é percorrido e é gerado um arquivo .csv com as seguintes informações de cada arquivo de áudio:\n",
    "\n",
    "* Caminho relativo do arquivo no dataset\n",
    "* Nome do locutor\n",
    "* Código identificador do locutor\n",
    "* Gênero do locutor (extraído de seu código identificador)\n",
    "* Duração do áudio (em segundos)\n",
    "* Rótulo do áudio (\"spoof\" ou \"bona-fide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the duration of an audio\n",
    "import librosa\n",
    "\n",
    "def get_duration(filename):\n",
    "    try:\n",
    "        audio_path = os.path.join(PATH_TO_DATASET, filename)\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        return librosa.get_duration(y=y, sr=sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load file {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list containing the path, speaker info, audio duration and label for each file.\n",
    "fake_audios_path = os.path.join(PATH_TO_DATASET, \"fake_voices\")\n",
    "real_audios_path = os.path.join(PATH_TO_DATASET, \"real_voices\")\n",
    "all_files = []\n",
    "\n",
    "# For every spoofed file, add its metadata to the list\n",
    "for folder in os.listdir(fake_audios_path):\n",
    "    folder_path = os.path.join(fake_audios_path, folder)\n",
    "    folder_files = os.listdir(folder_path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "    for filename in folder_files:\n",
    "        audio_path = os.path.join(\"fake_voices\", folder, filename)  # relative path\n",
    "        duration = get_duration(audio_path)\n",
    "        if duration is not None:\n",
    "            all_files.append([audio_path, person, ids, gender, duration, \"spoof\"])\n",
    "\n",
    "\n",
    "# For every bona-fide file, add its metadata to the list\n",
    "for folder in os.listdir(real_audios_path):\n",
    "    path = os.path.join(real_audios_path, folder)\n",
    "    folder_files = os.listdir(path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "    for filename in folder_files:\n",
    "        audio_path = os.path.join(\"real_voices\", folder, filename)\n",
    "        duration = get_duration(audio_path)\n",
    "        if duration is not None:\n",
    "            all_files.append([audio_path, person, ids, gender, duration, \"bona-fide\"])\n",
    "\n",
    "\n",
    "# Print the length of the list and the first 5 elements for visualization\n",
    "print(len(all_files))\n",
    "print(all_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the list to a .csv file.\n",
    "import csv\n",
    "\n",
    "fields = [\"file\", \"speaker\", \"id\", \"gender\", \"duration\", \"label\"]\n",
    "with open(os.path.join(PATH_TO_DATASET, \"meta.csv\"), \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    writer.writerows(all_files)\n",
    "\n",
    "print(\"File written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Análise exploratória dos dados <a class=\"anchor\" id=\"part_03\"></a>\n",
    "\n",
    "Nesta seção, o arquivo .csv contendo as informações de cada arquivo é carregado e é feita uma análise dos do conjunto de dados, em especial <completar com quais métricas serão avaliadas>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the .csv file exists\n",
    "[x for x in os.listdir(PATH_TO_DATASET) if x.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .csv file in a pandas dataframe\n",
    "dataset_metadata_df = pd.read_csv(os.path.join(PATH_TO_DATASET, 'meta.csv'), keep_default_na=False)\n",
    "dataset_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataframe is correct\n",
    "assert len(dataset_metadata_df) == 179814\n",
    "assert dataset_metadata_df.speaker.nunique() == dataset_metadata_df.id.nunique() == 101\n",
    "assert dataset_metadata_df.gender.nunique() == 2\n",
    "assert dataset_metadata_df.label.nunique() == 2\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total audio clips:\", dataset_metadata_df.duration.count())\n",
    "print(\"mean duration of audio clips (seconds):\", dataset_metadata_df.duration.mean())\n",
    "print(\"N speakers:\", dataset_metadata_df.speaker.nunique())\n",
    "print(\"Total audio time (hours):\", dataset_metadata_df.duration.sum() / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"audio samples per speaker\")\n",
    "dataset_metadata_df.speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minutes per speaker')\n",
    "dataset_metadata_df.groupby(\"speaker\")['duration'].sum().sort_values(ascending=False) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"samples by class\")\n",
    "dataset_metadata_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"minutes by class\")\n",
    "dataset_metadata_df.groupby(\"label\")['duration'].sum().sort_values(ascending=False) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the proportions of samples and duration are diferrent, why?\n",
    "print(\"duration mean of each class\")\n",
    "print(\"mean duration of spoof audios is bigger\")\n",
    "dataset_metadata_df.groupby(\"label\")['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quantity of each audio per speaker\")\n",
    "\n",
    "spoof_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'spoof'].groupby(\"speaker\").duration.count()\n",
    "bonafide_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'bona-fide'].groupby(\"speaker\").duration.count()\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "counts_df = pd.DataFrame({\n",
    "    'spoof_count': spoof_per_speaker,\n",
    "    'bona_fide_count': bonafide_per_speaker\n",
    "}).fillna(0)  # Fill NaN with 0 if some speakers have no 'spoof' or 'bona-fide' samples\n",
    "\n",
    "# Calculate total count and ratio for each speaker\n",
    "counts_df['total'] = counts_df['spoof_count'] + counts_df['bona_fide_count']\n",
    "counts_df['spoof_ratio'] = counts_df['spoof_count'] / counts_df['total']\n",
    "\n",
    "counts_df.sort_values(\"spoof_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minutes of each audio per speaker\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sum durations for each label per speaker, converting to minutes\n",
    "spoof_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'spoof'].groupby(\"speaker\").duration.sum() / 60\n",
    "bonafide_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'bona-fide'].groupby(\"speaker\").duration.sum() / 60\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "duration_df = pd.DataFrame({\n",
    "    'spoof_duration (min)': spoof_per_speaker,\n",
    "    'bona_fide_duration (min)': bonafide_per_speaker\n",
    "}).fillna(0)  # Fill NaN with 0 if some speakers have no 'spoof' or 'bona-fide' samples\n",
    "\n",
    "# Calculate total duration and ratio for each speaker\n",
    "duration_df['total_duration (min)'] = duration_df['spoof_duration (min)'] + duration_df['bona_fide_duration (min)']\n",
    "duration_df['spoof_ratio'] = duration_df['spoof_duration (min)'] / duration_df['total_duration (min)']\n",
    "\n",
    "# Sort by spoof ratio\n",
    "duration_df = duration_df.sort_values(\"spoof_ratio\")\n",
    "\n",
    "duration_df.sort_values(\"spoof_ratio\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
