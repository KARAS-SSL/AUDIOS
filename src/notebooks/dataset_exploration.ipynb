{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória do Conjunto de Dados\n",
    "\n",
    "### Sumário <a class=\"anchor\" id=\"topo\"></a>\n",
    "\n",
    "* [Parte 1: Configuração do notebook](#part_01)\n",
    "* [Parte 2: Geração do arquivo .csv](#part_02)\n",
    "* [Parte 3: Análise exploratória dos dados](#part_03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: Configuração do notebook <a class=\"anchor\" id=\"part_01\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, as bibliotecas que serão usadas são importadas e as variáveis globais são definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import matplotlib.patches as mpatches  # For custom legend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "PATH_TO_DATASET = \"/home/lozavival/Documents/AUDIOS/datasets/release/\"\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Geração do arquivo .csv <a class=\"anchor\" id=\"part_02\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, a estrutura de pastas do dataset é percorrida para criação de um arquivo .csv contendo informações de metadados dos arquivos presentes no dataset.\n",
    "\n",
    "Esse arquivo pode ser gerado em duas versões: uma listagem por pessoa, em que cada linha da tabela contém informações sobre um locutor, ou uma listagem por arquivo, em que cada linha da tabela contém informações sobre um arquivo de áudio específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listagem por arquivo, em que cada linha da tabela contém informações sobre um arquivo de áudio específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versão 1: Listagem por Pessoa\n",
    "\n",
    "Aqui, o dataset é percorrido e é gerado um arquivo .csv com as seguintes informações de cada pessoa:\n",
    "\n",
    "* Nome\n",
    "* Código identificador\n",
    "* Gênero (extraído do código identificador)\n",
    "* Quantidade de arquivos de fala sintetizada\n",
    "* Quantidade de arquivos de fala real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "[('Paula', {'gender': 'F', 'id': 'F026', 'spoof_count': 916, 'spoof_path': 'fake_voices/Paula_F026_Fake', 'bonafide_count': 1000, 'bonafide_path': 'real_voices/Paula_F026'}), ('MarcosBittencourt', {'gender': 'M', 'id': 'M006', 'spoof_count': 1000, 'spoof_path': 'fake_voices/MarcosBittencourt_M006_Fake', 'bonafide_count': 1000, 'bonafide_path': 'real_voices/MarcosBittencourt_M006'}), ('ClaudiaMoraes', {'gender': 'F', 'id': 'F023', 'spoof_count': 957, 'spoof_path': 'fake_voices/ClaudiaMoraes_F023_Fake', 'bonafide_count': 1000, 'bonafide_path': 'real_voices/ClaudiaMoraes_F023'}), ('JonatasPortugal', {'gender': 'M', 'id': 'M031', 'spoof_count': 840, 'spoof_path': 'fake_voices/JonatasPortugal_M031_Fake', 'bonafide_count': 1000, 'bonafide_path': 'real_voices/JonatasPortugal_M031'}), ('Regina', {'gender': 'F', 'id': 'F013', 'spoof_count': 990, 'spoof_path': 'fake_voices/Regina_F013_Fake', 'bonafide_count': 1000, 'bonafide_path': 'real_voices/Regina_F013'})]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary containing the name, id, gender and number of spoofed\n",
    "# and bonafide files for each person.\n",
    "fake_audios_path = os.path.join(PATH_TO_DATASET, \"fake_voices\")\n",
    "real_audios_path = os.path.join(PATH_TO_DATASET, \"real_voices\")\n",
    "people = {}\n",
    "\n",
    "# For every spoofed folder, get the number of spoofed files\n",
    "for folder in os.listdir(fake_audios_path):\n",
    "    path = os.path.join(fake_audios_path, folder)\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "\n",
    "    people[person] = {\n",
    "        \"gender\": gender,\n",
    "        \"id\": ids,\n",
    "        \"spoof_count\": len(files),\n",
    "        \"spoof_path\": os.path.join(\"fake_voices\", folder),\n",
    "    }\n",
    "\n",
    "# For every bona-fide folder, get the number of bona-fide files\n",
    "for folder in os.listdir(real_audios_path):\n",
    "    path = os.path.join(real_audios_path, folder)\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "\n",
    "    if people.get(person) is not None:\n",
    "        people[person][\"bonafide_count\"] = len(files)\n",
    "        people[person][\"bonafide_path\"] = os.path.join(\"real_voices\", folder)\n",
    "    else:\n",
    "        # If the person is not in the dictionary, there are no spoof files\n",
    "        people[person] = {\n",
    "            \"gender\": gender,\n",
    "            \"id\": ids,\n",
    "            \"spoof_count\": 0,\n",
    "            \"spoof_path\": None,\n",
    "            \"bonafide_count\": len(files),\n",
    "            \"bonafide_path\": os.path.join(\"real_voices\", folder),\n",
    "        }\n",
    "\n",
    "print(len(people))\n",
    "print(list(people.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written!\n"
     ]
    }
   ],
   "source": [
    "# Export the dictionary to a .csv file.\n",
    "\n",
    "fields = [\"person\", \"gender\", \"id\", \"spoof_count\", \"spoof_path\", \"bonafide_count\", \"bonafide_path\"]\n",
    "with open(os.path.join(PATH_TO_DATASET, \"people-meta.csv\"), \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    for person, data in people.items():\n",
    "        writer.writerow([person, data[\"gender\"], data[\"id\"], data[\"spoof_count\"], data[\"spoof_path\"], data[\"bonafide_count\"], data[\"bonafide_path\"]])\n",
    "\n",
    "print(\"File written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versão 2: Listagem por Arquivo\n",
    "\n",
    "O dataset é percorrido e é gerado um arquivo .csv com as seguintes informações de cada arquivo de áudio:\n",
    "\n",
    "* Caminho relativo do arquivo no dataset\n",
    "* Nome do locutor\n",
    "* Código identificador do locutor\n",
    "* Gênero do locutor (extraído de seu código identificador)\n",
    "* Duração do áudio (em segundos)\n",
    "* Rótulo do áudio (\"spoof\" ou \"bona-fide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the duration of an audio\n",
    "def get_duration(filename):\n",
    "    try:\n",
    "        audio_path = os.path.join(PATH_TO_DATASET, filename)\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        return librosa.get_duration(y=y, sr=sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load file {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get the amplitude of an audio\n",
    "def get_amplitude(filename):\n",
    "    try:\n",
    "        audio_path = os.path.join(PATH_TO_DATASET, filename)\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        return np.max(np.abs(y))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load file {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list containing the path, speaker info, audio duration and label for each file.\n",
    "fake_audios_path = os.path.join(PATH_TO_DATASET, \"fake_voices\")\n",
    "real_audios_path = os.path.join(PATH_TO_DATASET, \"real_voices\")\n",
    "all_files = []\n",
    "\n",
    "# For every spoofed file, add its metadata to the list\n",
    "for folder in os.listdir(fake_audios_path):\n",
    "    folder_path = os.path.join(fake_audios_path, folder)\n",
    "    folder_files = os.listdir(folder_path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "    for filename in folder_files:\n",
    "        audio_path = os.path.join(\"fake_voices\", folder, filename)  # relative path\n",
    "        duration = get_duration(audio_path)\n",
    "        if duration is not None:\n",
    "            all_files.append([audio_path, person, ids, gender, duration, \"spoof\"])\n",
    "\n",
    "\n",
    "# For every bona-fide file, add its metadata to the list\n",
    "for folder in os.listdir(real_audios_path):\n",
    "    path = os.path.join(real_audios_path, folder)\n",
    "    folder_files = os.listdir(path)\n",
    "\n",
    "    person, ids, *_ = folder.split(\"_\")\n",
    "    gender = ids[0]\n",
    "    for filename in folder_files:\n",
    "        audio_path = os.path.join(\"real_voices\", folder, filename)\n",
    "        duration = get_duration(audio_path)\n",
    "        if duration is not None:\n",
    "            all_files.append([audio_path, person, ids, gender, duration, \"bona-fide\"])\n",
    "\n",
    "\n",
    "# Print the length of the list and the first 5 elements for visualization\n",
    "print(len(all_files))\n",
    "print(all_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the list to a .csv file.\n",
    "\n",
    "fields = [\"file\", \"speaker\", \"id\", \"gender\", \"duration\", \"label\"]\n",
    "with open(os.path.join(PATH_TO_DATASET, \"meta.csv\"), \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    writer.writerows(all_files)\n",
    "\n",
    "print(\"File written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Análise exploratória dos dados <a class=\"anchor\" id=\"part_03\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4esta seção, o arquivo .csv contendo as informações de cada arquivo é carregado e é feita uma análise do conjunto de dados. Essa análise é dividida em três partes:\n",
    "\n",
    "* [Parte 3.1: Carregamento do dataframe](#part_03_01)\n",
    "\n",
    "    O dataframe é carregado e suas propriedades são verificadas.\n",
    "\n",
    "* [Parte 3.2: Visão geral dos dados](#part_03_02)\n",
    "\n",
    "    Aqui, é apresentada uma visão geral dos dados, fazendo uma análise da quantidade de arquivos e do número total de minutos de cada pessoa presente no dataset.\n",
    "\n",
    "* [Parte 3.3: Análise da amplitude dos áudios](#part_03_03)\n",
    "\n",
    "    Ao reproduzir alguns exemplos de cada classe, tem-se a impressão de que os áudios reais apresentam, de forma geral, uma amplitude muito menor que os áudios falsos. Assim, faz-se uma exploração para analisar se esse é realmente o caso.\n",
    "\n",
    "* [Parte 3.4: Análise do balanceamento do dataset](#part_03_04)\n",
    "\n",
    "    É feita uma análise do balanceamento dos dados entre as classes (\"spoof\" e \"bona-fide\") e entre os gêneros (masculino e feminino), verificando cada variável isoladamente e ambas variáveis em conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte 3.1: Carregamento do dataframe <a class=\"anchor\" id=\"part_03_01\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the .csv file exists\n",
    "[x for x in os.listdir(PATH_TO_DATASET) if x.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .csv file in a pandas dataframe\n",
    "dataset_metadata_df = pd.read_csv(os.path.join(PATH_TO_DATASET, 'meta_duration.csv'), keep_default_na=False)\n",
    "dataset_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataframe is correct\n",
    "assert len(dataset_metadata_df) == 179814\n",
    "assert dataset_metadata_df.speaker.nunique() == dataset_metadata_df.id.nunique() == 101\n",
    "assert dataset_metadata_df.gender.nunique() == 2\n",
    "assert dataset_metadata_df.label.nunique() == 2\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte 3.2: Visão geral dos dados <a class=\"anchor\" id=\"part_03_02\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total audio clips:\", dataset_metadata_df.duration.count())\n",
    "print(\"mean duration of audio clips (seconds):\", dataset_metadata_df.duration.mean())\n",
    "print(\"N speakers:\", dataset_metadata_df.speaker.nunique())\n",
    "print(\"Total audio time (hours):\", dataset_metadata_df.duration.sum() / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"audio samples per speaker\")\n",
    "speaker_counts = dataset_metadata_df.speaker.value_counts()\n",
    "print(speaker_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minutes per speaker')\n",
    "dataset_metadata_df.groupby(\"speaker\")['duration'].sum().sort_values(ascending=False) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quantity of each audio per speaker\")\n",
    "\n",
    "spoof_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'spoof'].groupby(\"speaker\").duration.count()\n",
    "bonafide_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'bona-fide'].groupby(\"speaker\").duration.count()\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "counts_df = pd.DataFrame({\n",
    "    'spoof_count': spoof_per_speaker,\n",
    "    'bona_fide_count': bonafide_per_speaker\n",
    "}).fillna(0)  # Fill NaN with 0 if some speakers have no 'spoof' or 'bona-fide' samples\n",
    "\n",
    "# Calculate total count and ratio for each speaker\n",
    "counts_df['total'] = counts_df['spoof_count'] + counts_df['bona_fide_count']\n",
    "counts_df['spoof_ratio'] = counts_df['spoof_count'] / counts_df['total']\n",
    "\n",
    "counts_df.sort_values(\"spoof_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minutes of each audio per speaker\")\n",
    "\n",
    "# Sum durations for each label per speaker, converting to minutes\n",
    "spoof_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'spoof'].groupby(\"speaker\").duration.sum() / 60\n",
    "bonafide_per_speaker = dataset_metadata_df[dataset_metadata_df.label == 'bona-fide'].groupby(\"speaker\").duration.sum() / 60\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "duration_df = pd.DataFrame({\n",
    "    'spoof_duration (min)': spoof_per_speaker,\n",
    "    'bona_fide_duration (min)': bonafide_per_speaker\n",
    "}).fillna(0)  # Fill NaN with 0 if some speakers have no 'spoof' or 'bona-fide' samples\n",
    "\n",
    "# Calculate total duration and ratio for each speaker\n",
    "duration_df['total_duration (min)'] = duration_df['spoof_duration (min)'] + duration_df['bona_fide_duration (min)']\n",
    "duration_df['spoof_ratio'] = duration_df['spoof_duration (min)'] / duration_df['total_duration (min)']\n",
    "\n",
    "# Sort by spoof ratio\n",
    "duration_df = duration_df.sort_values(\"spoof_ratio\")\n",
    "\n",
    "duration_df.sort_values(\"spoof_ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte 3.3: Análise da amplitude dos áudios <a class=\"anchor\" id=\"part_03_03\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to get aplitudes and add them as a new column\n",
    "dataset_metadata_df['amplitude'] = dataset_metadata_df['file'].progress_apply(get_amplitude)\n",
    "print(\"duration of amplitudes done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "dataset_metadata_df.to_csv(os.path.join(PATH_TO_DATASET, \"meta_with_amplitudes.csv\"), index=False)\n",
    "print(\"meta_with_amplitudes.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"amplitude mean of each class\")\n",
    "dataset_metadata_df.groupby(\"label\")['amplitude'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=dataset_metadata_df, x='label', y='amplitude')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Boxplot of Audio Amplitude per Class\", fontsize=14)\n",
    "plt.xlabel(\"Class\", fontsize=12)\n",
    "plt.ylabel(\"Duration (Seconds)\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"amplitude mean of each gender\")\n",
    "dataset_metadata_df.groupby(\"gender\")['amplitude'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"amplitude mean of each class, divided by gender\")\n",
    "dataset_metadata_df.groupby([\"label\", \"gender\"])['amplitude'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=dataset_metadata_df, x='label', y='amplitude', hue='gender', palette='pastel')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Boxplot of Audio Amplitude per Class and Gender\", fontsize=14)\n",
    "plt.xlabel(\"Class\", fontsize=12)\n",
    "plt.ylabel(\"Amplitude\", fontsize=12)\n",
    "plt.legend(title=\"Gender\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte 3.4: Análise do balanceamento <a class=\"anchor\" id=\"part_03_04\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parte 3.4.1: Balanceamento por Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"samples by class\")\n",
    "dataset_metadata_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"minutes by class\")\n",
    "dataset_metadata_df.groupby(\"label\")['duration'].sum().sort_values(ascending=False) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration mean of each class\")\n",
    "dataset_metadata_df.groupby(\"label\")['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=dataset_metadata_df, x='label', y='duration')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Boxplot of Audio Duration per Class\", fontsize=14)\n",
    "plt.xlabel(\"Class\", fontsize=12)\n",
    "plt.ylabel(\"Duration (Seconds)\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parte 3.4.2: Balanceamento por Gênero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"samples by gender\")\n",
    "dataset_metadata_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"minutes by gender\")\n",
    "dataset_metadata_df.groupby(\"gender\")['duration'].sum().sort_values(ascending=False) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration mean of each gender\")\n",
    "dataset_metadata_df.groupby(\"gender\")['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=dataset_metadata_df, x='gender', y='duration')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Boxplot of Audio Duration per Gender\", fontsize=14)\n",
    "plt.xlabel(\"Gender\", fontsize=12)\n",
    "plt.ylabel(\"Duration (Seconds)\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parte 3.4.3: Balanceamento por Classe e Gênero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"samples by class and gender\")\n",
    "dataset_metadata_df.groupby(['label', 'gender']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"minutes by class and gender\")\n",
    "dataset_metadata_df.groupby([\"label\", \"gender\"])['duration'].sum().sort_values(ascending=False) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data: Total duration grouped by class and gender, converted to minutes\n",
    "grouped_data = dataset_metadata_df.groupby(['label', 'gender'])['duration'].sum().reset_index()\n",
    "grouped_data['duration_minutes'] = grouped_data['duration'] / 60  # Convert to minutes\n",
    "\n",
    "# Create the bar plot using Seaborn\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(\n",
    "    data=grouped_data,\n",
    "    x='label',  # Group by class\n",
    "    y='duration_minutes',  # Total duration in minutes\n",
    "    hue='gender',  # Separate bars by gender\n",
    "    palette='pastel'\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Total Minutes per Class and Gender\", fontsize=14)\n",
    "plt.xlabel(\"Class\", fontsize=12)\n",
    "plt.ylabel(\"Total Duration (Minutes)\", fontsize=12)\n",
    "plt.legend(title=\"Gender\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration mean of each class and gender\")\n",
    "dataset_metadata_df.groupby([\"label\", \"gender\"])['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=dataset_metadata_df, x='label', y='duration', hue='gender', palette='pastel')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Boxplot of Audio Duration per Class and Gender\", fontsize=14)\n",
    "plt.xlabel(\"Class\", fontsize=12)\n",
    "plt.ylabel(\"Duration (Seconds)\", fontsize=12)\n",
    "plt.legend(title=\"Gender\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Voltar ao topo](#topo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
